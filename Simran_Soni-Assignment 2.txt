--1. GOALS:
--A. Query data in s3 from snowflake.
--B. Create view over data in aws s3.
--C. Disadvantages and advantages of this approach.

--2. PREPARATION : Upload some sample data from snowflake to s3.

-- Step 1. Creating Database & Schema 
CREATE DATABASE DEMO_DB;
CREATE SCHEMA PUBLIC;

-- Step 2. Creating transient table
CREATE OR REPLACE TRANSIENT TABLE DEMO_DB.PUBLIC.CUSTOMER_TEST
AS
SELECT * FROM 
"SNOWFLAKE_SAMPLE_DATA"."TPCDS_SF100TCL"."CUSTOMER";


SELECT * FROM CUSTOMER_TEST;

-- Step 3. Creating file format
create or replace file format my_csv_unload_format
type = csv field_delimiter = ',' skip_header = 1 null_if = ('NULL', 'null') empty_field_as_null = true compression = gzip;


-- Step 4. Creating Integration object 

create or replace storage integration s3_csv_int		
  type = external_stage		
  storage_provider = s3		
  enabled = true		
  storage_aws_role_arn = 'arn:aws:iam::227122424608:role/CSV-Sn'		
  storage_allowed_locations = ('s3://snowflake-22-07/csv-file/');


desc integration s3_csv_int;

-- Step 5. Creating external stage 
create or replace stage my_s3_unload_stage
  storage_integration = s3_csv_int
  url = 's3://snowflake-22-07/csv-file/'
  file_format = my_csv_unload_format;

-- Step 6. Copy into stage
COPY INTO @DEMO_DB.PUBLIC.MY_S3_UNLOAD_STAGE/Customer_data/
from
DEMO_DB.PUBLIC.customer_test;

--FILES SUCCESSFULLY UNLOADED INTO S3 BUCKET--


--3. QUERY DATA IN S3 FROM SNOWFLAKE


--Query this data in s3 from snowflake.

SELECT $1 C_CUSTOMER_SK,
$2 C_CUSTOMER_ID ,
$3 C_CURRENT_CDEMO_SK ,
$4 C_CURRENT_HDEMO_SK ,
$5 C_CURRENT_ADDR_SK,
$6 C_FIRST_SHIPTO_DATE_SK ,
$7 C_FIRST_SALES_DATE_SK ,
$8 C_SALUTATION ,
$9 C_FIRST_NAME ,
$10 C_LAST_NAME,
$11 C_PREFERRED_CUST_FLAG ,
$12 C_BIRTH_DAY ,
$13 C_BIRTH_MONTH ,
$14 C_BIRTH_YEAR,
$16 C_LOGIN ,
$17 C_EMAIL_ADDRESS ,
$18 C_LAST_REVIEW_DATE
FROM @DEMO_DB.PUBLIC.MY_S3_UNLOAD_STAGE/Customer_data/ 
(file_format => DEMO_DB.PUBLIC.MY_CSV_UNLOAD_FORMAT);


--Filter data directly from s3--
SELECT $1 C_CUSTOMER_SK,
$2 C_CUSTOMER_ID ,
$3 C_CURRENT_CDEMO_SK ,
$4 C_CURRENT_HDEMO_SK ,
$5 C_CURRENT_ADDR_SK,
$6 C_FIRST_SHIPTO_DATE_SK ,
$7 C_FIRST_SALES_DATE_SK ,
$8 C_SALUTATION ,
$9 C_FIRST_NAME ,
$10 C_LAST_NAME,
$11 C_PREFERRED_CUST_FLAG ,
$12 C_BIRTH_DAY ,
$13 C_BIRTH_MONTH ,
$14 C_BIRTH_YEAR,
$16 C_LOGIN ,
$17 C_EMAIL_ADDRESS ,
$18 C_LAST_REVIEW_DATE
FROM @DEMO_DB.PUBLIC.MY_S3_UNLOAD_STAGE/Customer_data/
(file_format =>  DEMO_DB.PUBLIC.MY_CSV_UNLOAD_FORMAT)
WHERE C_CUSTOMER_SK ='64596949';


--Execute group by
SELECT $9 C_FIRST_NAME,$10 C_LAST_NAME,COUNT(*)
FROM @DEMO_DB.PUBLIC.MY_S3_UNLOAD_STAGE/Customer_data/
(file_format => DEMO_DB.PUBLIC.MY_CSV_UNLOAD_FORMAT)
GROUP BY $9,$10;



--4. CREATE VIEW OVER S3 DATA

CREATE OR REPLACE VIEW CUSTOMER_DATA
AS
SELECT $1 C_CUSTOMER_SK,
$2 C_CUSTOMER_ID ,
$3 C_CURRENT_CDEMO_SK ,
$4 C_CURRENT_HDEMO_SK ,
$5 C_CURRENT_ADDR_SK,
$6 C_FIRST_SHIPTO_DATE_SK ,
$7 C_FIRST_SALES_DATE_SK ,
$8 C_SALUTATION ,
$9 C_FIRST_NAME ,
$10 C_LAST_NAME,
$11 C_PREFERRED_CUST_FLAG ,
$12 C_BIRTH_DAY ,
$13 C_BIRTH_MONTH ,
$14 C_BIRTH_YEAR,
$16 C_LOGIN ,
$17 C_EMAIL_ADDRESS ,
$18 C_LAST_REVIEW_DATE
FROM @DEMO_DB.PUBLIC.MY_S3_UNLOAD_STAGE/Customer_data/
(file_format => DEMO_DB.PUBLIC.MY_CSV_UNLOAD_FORMAT);

--Query data directly on view
SELECT * FROM CUSTOMER_DATA;


--Question: Now we can directly query data from s3 through view. What is the disadvantage of using 
--this approach ? Can you see partitions being scanned in the backend ?

--Answer: Disadvantages of this approach is: Data needs to be fetched from S3 storage which can be time consuming. This can results in more latency compared to querying data stored in Snowflake.
--There is no partitions scanned in this process. 


--Joining the view we created with a table on snowflake:
--Create a sample snowflake table as below

Create or replace transient table CUSTOMER_SNOWFLAKE_TABLE
AS
SELECT * FROM CUSTOMER_TEST limit 10000;

--Joining this with the view we created earlier:
SELECT B.* 
FROM CUSTOMER_SNOWFLAKE_TABLE B
LEFT OUTER JOIN 
CUSTOMER_DATA A
ON
A.C_CUSTOMER_SK = B.C_CUSTOMER_SK;


--Question: Now we successfully joined data in s3 with snowflake table. It may look simple but this 
--approach has lot of potential. Can you mention few below?

--Answer: The potentials are as follow: 
--1. Saving Storage Cost: Storing large datasets in S3 can be more cost-effective than storing them in Snowflake.
--2. Flexibility in storage capacity:  S3 provides virtually unlimited storage capacity which is ideal for storing large datasets.
--3. Diverse data analysis: By integrating data with other external storage providers like S3, Azure helps in in-depth data explorations.

--Question: How many partitions got scanned from snowflake table?

--Answer: Partitions scanned are - 356


--5. UNLOAD DATA BACK TO S3


COPY INTO @DEMO_DB.PUBLIC.MY_S3_UNLOAD_STAGE/Customer_joined_data/
from(
SELECT B.* 
FROM CUSTOMER_SNOWFLAKE_TABLE B
LEFT OUTER JOIN 
CUSTOMER_DATA A
ON
A.C_CUSTOMER_SK = B.C_CUSTOMER_SK
);


--6. ADVANTAGES AND DISADVANTAGES  OF THIS APPROACH
--Advantages:

--1. As compared with snowflake storage cost, AWS S3 external storage is cost efficient.
--2. Ease of Querying external data: Snowflake provides ease of querying external data using snowflake interface.
--3. Easy and secured sharing of data with external cloud services like AWS without moving the data from S3.


--Disadvantages:
--1. Delayed query results: When querying data from S3 it is slower as compared to querying data stored on snowflake.
--2. Performance of external data queries can be complex.

